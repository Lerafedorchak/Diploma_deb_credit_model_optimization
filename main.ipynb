{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2pVdkeef3hUG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "PGyEOWRI3zZv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = [f for f in os.listdir( if f.startswith('HC_2023_2024_ACT_DATA_HIST'))] #reading data about the acts\n",
        "dfs = []\n",
        "for file in files:\n",
        "  data = pd.read_excel(file)\n",
        "  dfs.append(data)\n",
        "act_data = pd.concat(dfs, ignore_index=True)\n",
        "act_data"
      ],
      "metadata": {
        "id": "qcfFiWRe3-KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = [f for f in os.listdir( if f.startswith('HC_2023_2024_ACT_DATA_HIST'))] #reading data about the acts\n",
        "dfs = []\n",
        "for file in files:\n",
        "  data = pd.read_excel(file)\n",
        "  dfs.append(data)\n",
        "act_data = pd.concat(dfs, ignore_index=True)\n",
        "act_data"
      ],
      "metadata": {
        "id": "YTR3wZ1q4hSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "general = pd.read_excel('HC_2023_2024_GENERAL_DATA_HIST_20250211.xlsx')\n",
        "general"
      ],
      "metadata": {
        "id": "Wpxe1mmY4oAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pogash = pd.read_excel('HC_2023_2024_TRAN_SUM_DATA_HIST_20250211.xlsx')\n",
        "pogash"
      ],
      "metadata": {
        "id": "c9glyTAa5DIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = [f for f in os.listdir( if f.startswith('CLID_CRM_DATA'))] #reading data about the acts\n",
        "dfs = []\n",
        "for file in files:\n",
        "  data = pd.read_excel(file)\n",
        "  dfs.append(data)\n",
        "predictors = pd.concat(dfs, ignore_index=True)\n",
        "predictors"
      ],
      "metadata": {
        "id": "lp3bTPp65RSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = [f for f in os.listdir( if f.startswith('CLID_TRAN_DATA_PR'))] #reading data about the acts\n",
        "dfs = []\n",
        "for file in files:\n",
        "  data = pd.read_excel(file)\n",
        "  dfs.append(data)\n",
        "predictors_2 = pd.concat(dfs, ignore_index=True)\n",
        "predictors_2"
      ],
      "metadata": {
        "id": "BFxH2TkK5aVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = [f for f in os.listdir( if f.startswith('CLID_INFO_DATA'))] #reading data about the acts\n",
        "dfs = []\n",
        "for file in files:\n",
        "  data = pd.read_excel(file)\n",
        "  dfs.append(data)\n",
        "predictors_3 = pd.concat(dfs, ignore_index=True)\n",
        "predictors_3"
      ],
      "metadata": {
        "id": "q0Hfm6NR5gaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing model"
      ],
      "metadata": {
        "id": "fYFF5Pqx557R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "devtp1Nu5l8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action_map = {\n",
        "    \"ДЗВОНОУ\": 0,\n",
        "    \"МЕСЕНДЖЕР\": 1,\n",
        "    \"ВИЕЗД\": 2,\n",
        "    \"МЕСЕНДЖЕР 3-ОС\": 3,\n",
        "    \"ПИСЬМО\": 4,\n",
        "    \"ДЗВОНОК 3-ОС\": 5,\n",
        "    \"ВИЕЗД 3-ОС\": 6\n",
        "}\n",
        "\n",
        "act_data['action_encoded'] = act_data['action'].map(action_map)\n"
      ],
      "metadata": {
        "id": "dd9Ks0OJ58lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "vLW2gt8P6Vfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = xgb.XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=7,\n",
        "    n_estimators=100,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42\n"
      ],
      "metadata": {
        "id": "mMi_DfUe6cVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "A6IFoMJC6gBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "Zb0g9Pdp6jr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "cGLdPihb6kW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inv_map = {v: k for k, v in action_map.items()}\n",
        "\n",
        "predictions_text = [inv_map[i] for i in y_pred]\n",
        "print(predictions_text[:20])\n"
      ],
      "metadata": {
        "id": "Garvh5h26oAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.1, 0.05, 0.01],\n",
        "    'gamma': [0, 0.1, 0.3],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'reg_alpha': [0, 0.5, 1],\n",
        "    'reg_lambda': [1, 2]\n",
        "}\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=7,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=xgb_clf,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "print(\"Best params from GridSearch:\")\n",
        "print(grid.best_params_)\n",
        "\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "print(\"\\nClassification Report on Test Set:\")\n",
        "print(classification_report(y_test, y_pred_best))\n"
      ],
      "metadata": {
        "id": "SBwmdlF96rXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb.plot_importance(model)"
      ],
      "metadata": {
        "id": "UmPlGk917H_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb.plot_importance(best_model)"
      ],
      "metadata": {
        "id": "zH46CXdv7L_X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}